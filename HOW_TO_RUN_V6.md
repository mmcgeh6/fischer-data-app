# How to Run Fischer Data App V6

## What's New in V6

Version 6 introduces significant improvements over V5:

### Key Changes
- ‚úÖ **Parallel AI Analysis**: All files analyzed simultaneously (much faster!)
- ‚úÖ **Simplified Configuration**: Single `start_row` parameter (removed confusing `skip_rows` + `header_row`)
- ‚úÖ **No Excel Time Column**: Removed all Excel Time handling (was a data artifact from sample files)
- ‚úÖ **Batch Processing**: One button analyzes all uploaded files at once
- ‚úÖ **Enhanced Debug Panel**: View all API calls and responses in one place

### Breaking Changes from V5
- Excel Time column no longer supported or required
- Configuration uses `start_row` instead of separate `skip_rows` and `header_row`
- AI JSON response simplified: `{delimiter, start_row, date_column, value_column, sensor_name}`

## Prerequisites

1. **API Key Setup**: Ensure your `.env` file has the Claude API key:
   ```bash
   CLAUDE_API_KEY=sk-ant-api03-...your-key-here...
   ```

2. **Python Environment**: Make sure you have all dependencies installed:
   ```bash
   pip install -r requirements.txt
   ```

## Running the Application

### Start the App
```bash
streamlit run src/app_v6.py
```

The app will open in your default web browser at `http://localhost:8501`

### Restarting the App

If you need to restart (e.g., after making code changes):

1. **In the terminal**: Press `Ctrl+C` to stop the server
2. **Run again**: `streamlit run src/app_v6.py`

Or use the "Rerun" button in the Streamlit interface (top-right corner).

## Using the App

### Step 1: Upload Files
- Click "Browse files" and select all your sensor data files (Excel or CSV)
- The app supports 10-90 files at once
- All files are saved to a temporary directory

### Step 2: AI Analysis
- Click **"ü§ñ Analyze All Files"** button
- The app will:
  - Read first 15 rows from each file
  - Send parallel API requests to Claude
  - Auto-detect: delimiter, start_row, date_column, value_column, sensor_name
  - Show progress and summary

### Step 3: Review & Edit
- Review AI-detected configurations for each file
- Edit any incorrect detections using the input fields:
  - **Start Row**: Row where column headers are located (0-based)
  - **Delimiter**: Comma, Tab, Semicolon, or Pipe
  - **Date Column**: Column index for timestamps (0-based)
  - **Value Column**: Column index for sensor readings (0-based)
  - **Sensor Name**: Name for this sensor in the output
- Click "View data preview" to verify settings

### Step 4: Combine Data
- Click **"üîó Combine All Files"** button
- The app merges all files using outer join on Date column
- View summary metrics and data preview

### Step 5: Export
- Enter output filename (auto-generated by default)
- Click **"üì• Generate CSV"** button
- Download the combined data file
- Check statistics in the expandable section

## AI Debug Panel

The debug panel at the bottom shows:
- Total API calls and success rate
- Individual file analysis details
- Full request prompts and response JSON
- Error messages for failed analyses

This is useful for:
- Verifying AI detection accuracy
- Troubleshooting configuration issues
- Understanding why a file might have failed

## Troubleshooting

### API Key Not Found
```
‚ö†Ô∏è CLAUDE_API_KEY not found in .env file
```
**Solution**: Create or update `.env` file in project root with your API key.

### File Parse Error
```
Could not parse file with current settings
```
**Solution**:
1. Check the "View data preview" expander
2. Adjust start_row or delimiter settings
3. Verify file format is valid CSV/Excel

### AI Analysis Failed
Check the Debug Panel for specific error messages:
- **JSON decode error**: AI didn't return valid JSON (retry or adjust manually)
- **API call error**: Network or API key issue
- **Timeout**: File too complex or API slow (configurations should still work, retry if needed)

### No Data After Combine
- Verify date columns are being parsed correctly
- Check that value columns contain numeric data
- Look for timezone or date format inconsistencies

## Performance Notes

- **Parallel Processing**: V6 analyzes all files simultaneously using ThreadPoolExecutor
- **API Calls**: Expect 1-3 seconds per file, but multiple files run in parallel
- **Max Workers**: Currently set to 5 concurrent API calls (configurable in code)
- **Memory**: Each file loaded once into memory during combine step

## Comparing with Previous Versions

| Feature | V5 | V6 |
|---------|----|----|
| AI Analysis | Per-file (sequential) | All files (parallel) |
| Config Params | skip_rows + header_row | start_row (simplified) |
| Excel Time | Supported | Removed |
| Speed | Slower (sequential) | Faster (parallel) |
| Debug Panel | Per-file expandable | Unified panel |

## Next Steps

After getting familiar with V6:
1. Process your production data files
2. Review the combined output for accuracy
3. Use the data_processor.py module for resampling (if needed)
4. Set up automated batch processing for regular data loads

For additional help, see:
- `CLAUDE.md` - Full project documentation
- `HOW_TO_USE.md` - General usage guide
- `README.md` - Project overview
